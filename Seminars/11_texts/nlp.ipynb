{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import roc_auc_score, f1_score, classification_report\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбивка данных на трейн и тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Spam_SMS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5574 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5569  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5570   ham               Will ü b going to esplanade fr home?\n",
       "5571   ham  Pity, * was in mood for that. So...any other s...\n",
       "5572   ham  The guy did some bitching but I acted like i'd...\n",
       "5573   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5574 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = LabelEncoder().fit_transform(data.Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['Message']\n",
    "y = data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели\n",
    "Для того, чтобы обучить базовые модели на текстовых данных можно воспользоваться:\n",
    "1. TF-IDF\n",
    "2. Bag-of-words\n",
    "3. Нейросетевые алгоритмы (w2v) + усреднение\n",
    "\n",
    "Для лучшей работы:\n",
    "1. Добавляем токенизацию (обрабатываем посимвольно или по словам)\n",
    "2. Удаление лишних символов\n",
    "3. Приведение к нормальной форме\n",
    "\n",
    "Поверх этого накидываем классические алгоритмы (Бустинг, логрег и т.д,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X)\n",
    "X_train_transformed = vectorizer.transform(X_train).toarray()\n",
    "X_test_transformed = vectorizer.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4180, 8713)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1394, 8713)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_transformed, y_train)\n",
    "preds = model.predict_proba(X_test_transformed)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9886126742480622"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8389057750759878"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, (preds>=0.5).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1203\n",
      "           1       1.00      0.72      0.84       191\n",
      "\n",
      "    accuracy                           0.96      1394\n",
      "   macro avg       0.98      0.86      0.91      1394\n",
      "weighted avg       0.96      0.96      0.96      1394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, (preds>=0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поиграем с токенизацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1203\n",
      "           1       1.00      0.66      0.79       191\n",
      "\n",
      "    accuracy                           0.95      1394\n",
      "   macro avg       0.97      0.83      0.88      1394\n",
      "weighted avg       0.96      0.95      0.95      1394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1, 3))),\n",
    "    ('model',  LogisticRegression())\n",
    "    ]\n",
    ")\n",
    "pipe.fit(X_train, y_train)\n",
    "preds = pipe.predict_proba(X_test)[:, 1]\n",
    "print(classification_report(y_test, (preds>=0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1203\n",
      "           1       0.99      0.80      0.88       191\n",
      "\n",
      "    accuracy                           0.97      1394\n",
      "   macro avg       0.98      0.90      0.93      1394\n",
      "weighted avg       0.97      0.97      0.97      1394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1, 1))),\n",
    "    ('model',  LogisticRegression())\n",
    "    ]\n",
    ")\n",
    "pipe.fit(X_train, y_train)\n",
    "preds = pipe.predict_proba(X_test)[:, 1]\n",
    "print(classification_report(y_test, (preds>=0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1203\n",
      "           1       1.00      0.86      0.93       191\n",
      "\n",
      "    accuracy                           0.98      1394\n",
      "   macro avg       0.99      0.93      0.96      1394\n",
      "weighted avg       0.98      0.98      0.98      1394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(analyzer='char', ngram_range=(1, 4))),\n",
    "    ('model',  LogisticRegression())\n",
    "    ]\n",
    ")\n",
    "pipe.fit(X_train, y_train)\n",
    "preds = pipe.predict_proba(X_test)[:, 1]\n",
    "print(classification_report(y_test, (preds>=0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробуем удалить избыточную информацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1203\n",
      "           1       0.99      0.87      0.93       191\n",
      "\n",
      "    accuracy                           0.98      1394\n",
      "   macro avg       0.98      0.94      0.96      1394\n",
      "weighted avg       0.98      0.98      0.98      1394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(analyzer='char', ngram_range=(1, 4), max_features=500)),\n",
    "    ('model',  LogisticRegression())\n",
    "    ]\n",
    ")\n",
    "pipe.fit(X_train, y_train)\n",
    "preds = pipe.predict_proba(X_test)[:, 1]\n",
    "print(classification_report(y_test, (preds>=0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробуем воспользоваться BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1203\n",
      "           1       1.00      0.77      0.87       191\n",
      "\n",
      "    accuracy                           0.97      1394\n",
      "   macro avg       0.98      0.88      0.93      1394\n",
      "weighted avg       0.97      0.97      0.97      1394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(analyzer='char', ngram_range=(1, 4), max_features=500, use_idf=False)),\n",
    "    ('model',  LogisticRegression())\n",
    "    ]\n",
    ")\n",
    "pipe.fit(X_train, y_train)\n",
    "preds = pipe.predict_proba(X_test)[:, 1]\n",
    "print(classification_report(y_test, (preds>=0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/slavyan/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4044    I am literally in bed and have been up for lik...\n",
       "2586         I will be outside office take all from there\n",
       "5159                              K k:) sms chat with me.\n",
       "585     So how's scotland. Hope you are not over showi...\n",
       "4574    \"URGENT! This is the 2nd attempt to contact U!...\n",
       "                              ...                        \n",
       "3772    Hi, wlcome back, did wonder if you got eaten b...\n",
       "5191    ree entry in 2 a weekly comp for a chance to w...\n",
       "5226    \"OH FUCK. JUSWOKE UP IN A BED ON A BOATIN THE ...\n",
       "5390             NOT MUCH NO FIGHTS. IT WAS A GOOD NITE!!\n",
       "860               Did he just say somebody is named tampa\n",
       "Name: Message, Length: 4180, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4044    I am literally in bed and have been up for lik...\n",
       "2586         I will be outside office take all from there\n",
       "5159                               K k:) sm chat with me.\n",
       "585     So how's scotland. Hope you are not over showi...\n",
       "4574    \"URGENT! This is the 2nd attempt to contact U!...\n",
       "                              ...                        \n",
       "3772    Hi, wlcome back, did wonder if you got eaten b...\n",
       "5191    ree entry in 2 a weekly comp for a chance to w...\n",
       "5226    \"OH FUCK. JUSWOKE UP IN A BED ON A BOATIN THE ...\n",
       "5390             NOT MUCH NO FIGHTS. IT WAS A GOOD NITE!!\n",
       "860               Did he just say somebody is named tampa\n",
       "Name: Message, Length: 4180, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_prep = X_train.apply(lambda x: ' '.join([WordNetLemmatizer().lemmatize(w) for w in x.split()]))\n",
    "X_test_prep = X_test.apply(lambda x: ' '.join([WordNetLemmatizer().lemmatize(w) for w in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
