{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбивка данных на трейн и тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Spam_SMS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5574 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5569  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5570   ham               Will ü b going to esplanade fr home?\n",
       "5571   ham  Pity, * was in mood for that. So...any other s...\n",
       "5572   ham  The guy did some bitching but I acted like i'd...\n",
       "5573   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5574 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"target\"] = LabelEncoder().fit_transform(data.Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"Message\"]\n",
    "y = data[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели\n",
    "Для того, чтобы обучить базовые модели на текстовых данных можно воспользоваться:\n",
    "1. TF-IDF\n",
    "2. Bag-of-words\n",
    "3. Нейросетевые алгоритмы (w2v) + усреднение\n",
    "\n",
    "Для лучшей работы:\n",
    "1. Добавляем токенизацию (обрабатываем посимвольно или по словам)\n",
    "2. Удаление лишних символов\n",
    "3. Приведение к нормальной форме\n",
    "\n",
    "Поверх этого накидываем классические алгоритмы (Бустинг, логрег и т.д,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X)\n",
    "X_train_transformed = vectorizer.transform(X_train).toarray()\n",
    "X_test_transformed = vectorizer.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4180, 8713)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1394, 8713)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_transformed, y_train)\n",
    "preds = model.predict_proba(X_test_transformed)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9886126742480622"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8389057750759878"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, (preds >= 0.5).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1203\n",
      "           1       1.00      0.72      0.84       191\n",
      "\n",
      "    accuracy                           0.96      1394\n",
      "   macro avg       0.98      0.86      0.91      1394\n",
      "weighted avg       0.96      0.96      0.96      1394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, (preds >= 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поиграем с токенизацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1203\n",
      "           1       1.00      0.66      0.79       191\n",
      "\n",
      "    accuracy                           0.95      1394\n",
      "   macro avg       0.97      0.83      0.88      1394\n",
      "weighted avg       0.96      0.95      0.95      1394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer(analyzer=\"word\", ngram_range=(1, 3))),\n",
    "    (\"model\", LogisticRegression())\n",
    "])\n",
    "pipe.fit(X_train, y_train)\n",
    "preds = pipe.predict_proba(X_test)[:, 1]\n",
    "print(classification_report(y_test, (preds >= 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1203\n",
      "           1       0.99      0.80      0.88       191\n",
      "\n",
      "    accuracy                           0.97      1394\n",
      "   macro avg       0.98      0.90      0.93      1394\n",
      "weighted avg       0.97      0.97      0.97      1394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer(analyzer=\"word\", ngram_range=(1, 1))),\n",
    "    (\"model\", LogisticRegression())\n",
    "])\n",
    "pipe.fit(X_train, y_train)\n",
    "preds = pipe.predict_proba(X_test)[:, 1]\n",
    "print(classification_report(y_test, (preds >= 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1203\n",
      "           1       1.00      0.86      0.93       191\n",
      "\n",
      "    accuracy                           0.98      1394\n",
      "   macro avg       0.99      0.93      0.96      1394\n",
      "weighted avg       0.98      0.98      0.98      1394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer(analyzer=\"char\", ngram_range=(1, 4))),\n",
    "    (\"model\", LogisticRegression())\n",
    "])\n",
    "pipe.fit(X_train, y_train)\n",
    "preds = pipe.predict_proba(X_test)[:, 1]\n",
    "print(classification_report(y_test, (preds >= 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробуем удалить избыточную информацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1203\n",
      "           1       0.99      0.87      0.93       191\n",
      "\n",
      "    accuracy                           0.98      1394\n",
      "   macro avg       0.98      0.94      0.96      1394\n",
      "weighted avg       0.98      0.98      0.98      1394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"vectorizer\", TfidfVectorizer(analyzer=\"char\", ngram_range=(1, 4), max_features=500)),\n",
    "        (\"model\", LogisticRegression()),\n",
    "    ]\n",
    ")\n",
    "pipe.fit(X_train, y_train)\n",
    "preds = pipe.predict_proba(X_test)[:, 1]\n",
    "print(classification_report(y_test, (preds >= 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробуем воспользоваться BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1203\n",
      "           1       1.00      0.77      0.87       191\n",
      "\n",
      "    accuracy                           0.97      1394\n",
      "   macro avg       0.98      0.88      0.93      1394\n",
      "weighted avg       0.97      0.97      0.97      1394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"vectorizer\", TfidfVectorizer(analyzer=\"char\", ngram_range=(1, 4), max_features=500, use_idf=False)),\n",
    "        (\"model\", LogisticRegression()),\n",
    "    ]\n",
    ")\n",
    "pipe.fit(X_train, y_train)\n",
    "preds = pipe.predict_proba(X_test)[:, 1]\n",
    "print(classification_report(y_test, (preds >= 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1203\n",
      "           1       0.97      0.94      0.95       191\n",
      "\n",
      "    accuracy                           0.99      1394\n",
      "   macro avg       0.98      0.97      0.97      1394\n",
      "weighted avg       0.99      0.99      0.99      1394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(analyzer=\"char\", ngram_range=(1, 4), max_features=500)),\n",
    "    (\"model\", LogisticRegression())\n",
    "])\n",
    "pipe.fit(X_train, y_train)\n",
    "preds = pipe.predict_proba(X_test)[:, 1]\n",
    "print(classification_report(y_test, (preds >= 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/vvh413/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10885"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "len(stopwords.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prep = X_train.apply(lambda x: \" \".join([WordNetLemmatizer().lemmatize(w) for w in x.lower().split()]))\n",
    "X_test_prep = X_test.apply(lambda x: \" \".join([WordNetLemmatizer().lemmatize(w) for w in x.lower().split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1203\n",
      "           1       0.99      0.80      0.88       191\n",
      "\n",
      "    accuracy                           0.97      1394\n",
      "   macro avg       0.98      0.90      0.93      1394\n",
      "weighted avg       0.97      0.97      0.97      1394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer(analyzer=\"word\", ngram_range=(1, 1))),\n",
    "    (\"model\", LogisticRegression())\n",
    "])\n",
    "pipe.fit(X_train_prep, y_train)\n",
    "preds = pipe.predict_proba(X_test_prep)[:, 1]\n",
    "print(classification_report(y_test, (preds >= 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import FastText, Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cats', 0.8099379539489746),\n",
       " ('dog', 0.760945737361908),\n",
       " ('kitten', 0.7464985251426697),\n",
       " ('feline', 0.7326234579086304),\n",
       " ('beagle', 0.7150582671165466),\n",
       " ('puppy', 0.7075453400611877),\n",
       " ('pup', 0.6934291124343872),\n",
       " ('pet', 0.6891531348228455),\n",
       " ('felines', 0.6755931973457336),\n",
       " ('chihuahua', 0.6709762215614319)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cossim(v1, v2):\n",
    "    return v1.dot(v2) / (np.sqrt(np.sum(v1**2)) * np.sqrt(np.sum(v2**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.22942673, 0.3161814, 0.65109557)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "cossim(wv[\"king\"], wv[\"man\"]), cossim(wv[\"queen\"], wv[\"woman\"]), cossim(wv[\"king\"], wv[\"queen\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73005176"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cossim(wv[\"king\"] - wv[\"man\"] + wv[\"woman\"], wv[\"queen\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([\n",
    "    wv.get_vector(w, norm=True) for w in X_train.iloc[0].lower().split() if w in wv.key_to_index], \n",
    "    axis=0\n",
    ") == wv.get_mean_vector(X_train.iloc[0].lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized = np.array(X_train.apply(lambda row: wv.get_mean_vector(row.lower().split())).tolist())\n",
    "X_test_vectorized = np.array(X_test.apply(lambda row: wv.get_mean_vector(row.lower().split())).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4180, 300), (1394, 300))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized.shape, X_test_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      1203\n",
      "           1       0.88      0.48      0.62       191\n",
      "\n",
      "    accuracy                           0.92      1394\n",
      "   macro avg       0.90      0.74      0.79      1394\n",
      "weighted avg       0.92      0.92      0.91      1394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "preds = model.predict(X_test_vectorized)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
